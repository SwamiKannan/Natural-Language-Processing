{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: filelock in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: sentencepiece in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (from transformers) (2020.5.14)\n",
      "Requirement already satisfied: requests in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (from transformers) (4.46.0)\n",
      "Requirement already satisfied: sacremoses in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: joblib in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (from sacremoses->transformers) (0.15.1)\n",
      "Requirement already satisfied: click in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in e:\\anaconda\\envs\\huggingface\\lib\\site-packages (from sacremoses->transformers) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import keras\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Utilities\n",
    "\n",
    "import os, zipfile, sys, warnings\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "from time import time\n",
    "\n",
    "# Numerical calculation\n",
    "import numpy as np\n",
    "\n",
    "# Data Handling\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "# from keras.layers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.initializers import Constant\n",
    "import re\n",
    "\n",
    "\n",
    "# Data Visualization\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "# Sequential Modeling\n",
    "# import keras.backend as K\n",
    "# from keras import initializers\n",
    "# from keras.engine.topology import Layer, InputSpec\n",
    "# from keras import Model, Sequential\n",
    "# from tensorflow.keras.layers import Dense, LSTM, TimeDistributed, Conv1D, MaxPooling1D\n",
    "# from tensorflow.keras.layers import Embedding, Activation, Dropout, Flatten, Bidirectional, Input\n",
    "from tensorflow.keras.layers import *\n",
    "# from tensorflow.keras.layers import Permute, merge, Input, multiply, concatenate\n",
    "# from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "# from keras.constraints import max_norm, unit_norm\n",
    "\n",
    "# Preprocessing and NLP library\n",
    "# from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# import nltk\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, accuracy_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_segments(sentences):\n",
    "    sentences_segments = []\n",
    "    for sent in sentences:\n",
    "      temp = []\n",
    "      i = 0\n",
    "      for token in sent.split(\" \"):\n",
    "        temp.append(i)\n",
    "        if token == \"[SEP]\":\n",
    "          i += 1\n",
    "      sentences_segments.append(temp)\n",
    "    return sentences_segments\n",
    "\n",
    "def _get_inputs(df,_maxlen,tokenizer,use_keras_pad=False):\n",
    "\n",
    "\n",
    "    maxqnans = np.int((_maxlen-20)/2)\n",
    "    pattern = '[^\\w\\s]+|\\n' # remove everything including newline (|\\n) other than words (\\w) or spaces (\\s)\n",
    "    \n",
    "    sentences = [\"[CLS] \" + \" \".join(tokenizer.tokenize(desc)[:maxqnans]) +\" [SEP] \" \n",
    "                for desc in df['Clean Description'].values.tolist()]\n",
    "              #train.head()[['question_title','question_body','answer','category']].values.tolist()]\n",
    "    \n",
    "\n",
    "    #generate masks\n",
    "    # bert requires a mask for the words which are padded. \n",
    "    # Say for example, maxlen is 100, sentence size is 90. then, [1]*90 + [0]*[100-90]\n",
    "    sentences_mask = [[1]*len(sent.split(\" \"))+[0]*(_maxlen - len(sent.split(\" \"))) for sent in sentences]\n",
    " \n",
    "    #generate input ids  \n",
    "    # if less than max length provided then the words are padded\n",
    "    if use_keras_pad:\n",
    "      sentences_padded = pad_sequences(sentences.split(\" \"), dtype=object, maxlen=10, value='[PAD]',padding='post')\n",
    "    else:\n",
    "      sentences_padded = [sent + \" [PAD]\"*(_maxlen-len(sent.split(\" \"))) if len(sent.split(\" \"))!=_maxlen else sent for sent in sentences ]\n",
    "\n",
    "    sentences_converted = [tokenizer.convert_tokens_to_ids(s.split(\" \")) for s in sentences_padded]\n",
    "    \n",
    "    #generate segments\n",
    "    # for each separation [SEP], a new segment is converted\n",
    "    sentences_segment = _get_segments(sentences_padded)\n",
    "\n",
    "    genLength = set([len(sent.split(\" \")) for sent in sentences_padded])\n",
    "\n",
    "    if _maxlen < 20:\n",
    "      raise Exception(\"max length cannot be less than 20\")\n",
    "    elif len(genLength)!=1: \n",
    "      print(genLength)\n",
    "      raise Exception(\"sentences are not of same size\")\n",
    "\n",
    "\n",
    "\n",
    "    #convert list into tensor integer arrays and return it\n",
    "    #return sentences_converted,sentences_segment, sentences_mask\n",
    "    #return [np.asarray(sentences_converted, dtype=np.int32), \n",
    "    #        np.asarray(sentences_segment, dtype=np.int32), \n",
    "    #        np.asarray(sentences_mask, dtype=np.int32)]\n",
    "    return [tf.cast(sentences_converted,tf.int32), tf.cast(sentences_segment,tf.int32), tf.cast(sentences_mask,tf.int32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer_transformer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assignment group</th>\n",
       "      <th>Clean Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>login issue verify user detail employee manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>outlook team meeting skype etc not appear cale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>can not log vpn not best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>unable access hr tool page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>skype error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Assignment group                                  Clean Description\n",
       "0                 0  login issue verify user detail employee manage...\n",
       "1                 0  outlook team meeting skype etc not appear cale...\n",
       "2                 0                           can not log vpn not best\n",
       "3                 0                         unable access hr tool page\n",
       "4                 0                                        skype error"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('model_df1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Clean Description'], df['Assignment group'], test_size=0.20, random_state=1, stratify=df['Assignment group'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6800,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_class=y_test.nunique()\n",
    "output_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr=pd.DataFrame(X_train)\n",
    "df_tr.columns = ['Clean Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts=pd.DataFrame(X_test)\n",
    "df_ts.columns = ['Clean Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tok=_get_inputs(df=df_ts,tokenizer=bert_tokenizer_transformer,_maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tok=_get_inputs(df=df_tr,tokenizer=bert_tokenizer_transformer,_maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6800, 100), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tok[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # token_inputs = Input(shape=(None,), name='word_inputs', dtype='int32')\n",
    "# # mask_inputs = Input(shape=(None,), name='word_inputs', dtype='int32')\n",
    "# # seg_inputs = Input(shape=(None,), name='word_inputs', dtype='int32')\n",
    "# inputs  = Input(shape=(None, ),dtype=tf.int32)\n",
    "token_inputs = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "mask_inputs = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "seg_inputs = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model=TFBertModel.from_pretrained(\"bert-base-uncased\",output_hidden_states=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'tf_bert_model/Identity:0' shape=(None, 100, 768) dtype=float32>,\n",
       " <tf.Tensor 'tf_bert_model/Identity_1:0' shape=(None, 768) dtype=float32>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model([token_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'tf_bert_model_1/Identity:0' shape=(None, 100, 768) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_output,_ = bert_model([token_inputs, mask_inputs, seg_inputs])\n",
    "seq_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = GlobalAveragePooling1D()(seq_output)\n",
    "X = Dense(128, activation='relu')(X)\n",
    "X = Dense(64, activation='relu')(X)\n",
    "output_= Dense(36, activation='softmax', name='output')(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_segments (InputLayer)     [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     ((None, 100, 768), ( 109482240   input_word_ids[0][0]             \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 input_segments[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          98432       global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 36)           2340        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 109,591,268\n",
      "Trainable params: 109,591,268\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model2 = Model([token_inputs, mask_inputs, seg_inputs],output_)\n",
    "bert_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat=to_categorical(np.array(y_train))\n",
    "y_test_cat=to_categorical(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6800, 36)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model2.compile(optimizer=opt, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'input_word_ids:0' shape=(None, 100) dtype=int32>,\n",
       " <tf.Tensor 'input_masks:0' shape=(None, 100) dtype=int32>,\n",
       " <tf.Tensor 'input_segments:0' shape=(None, 100) dtype=int32>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_inputs, mask_inputs, seg_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5440 samples, validate on 1360 samples\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "5440/5440 [==============================] - 216s 40ms/sample - loss: 2.5039 - val_loss: 2.4374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a0f46d47c8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model2.fit(X_train_tok,y_train_cat,epochs=1,batch_size = 18,validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5440 samples, validate on 1360 samples\n",
      "5440/5440 [==============================] - 198s 36ms/sample - loss: 2.4220 - val_loss: 2.4217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a111130808>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model2.fit(X_train_tok,y_train_cat,epochs=1,batch_size = 18,validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5440 samples, validate on 1360 samples\n",
      "5440/5440 [==============================] - 195s 36ms/sample - loss: 2.4120 - val_loss: 2.4230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a1110c40c8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model2.fit(X_train_tok,y_train_cat,epochs=1,batch_size = 18,validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5440 samples, validate on 1360 samples\n",
      "5440/5440 [==============================] - 199s 37ms/sample - loss: 2.4154 - val_loss: 2.4232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a1110b4888>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model2.fit(X_train_tok,y_train_cat,epochs=1,batch_size = 18,validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = bert_model2.predict(X_test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_proba > 0.5).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_summary(y_test, y_pred, y_proba):\n",
    "    print('\\033[1mModel accuracy:\\033[0m %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "    print('_'*80)\n",
    "    print('\\033[1mConfusion matrix:\\033[0m\\n %s' % (confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))))\n",
    "    print('_'*80)\n",
    "    print('\\033[1mClassification report:\\033[0m\\n %s' % (classification_report(y_test, y_pred)))\n",
    "    print('_'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5067068 , 0.00375882, 0.0268866 , ..., 0.0040921 , 0.00410931,\n",
       "        0.03255539],\n",
       "       [0.5067068 , 0.00375882, 0.0268866 , ..., 0.0040921 , 0.00410931,\n",
       "        0.03255539],\n",
       "       [0.50670683, 0.00375882, 0.0268866 , ..., 0.0040921 , 0.00410931,\n",
       "        0.0325554 ],\n",
       "       ...,\n",
       "       [0.50670683, 0.00375882, 0.02688659, ..., 0.0040921 , 0.00410931,\n",
       "        0.03255539],\n",
       "       [0.50670683, 0.00375882, 0.0268866 , ..., 0.0040921 , 0.00410931,\n",
       "        0.03255538],\n",
       "       [0.50670683, 0.00375882, 0.0268866 , ..., 0.0040921 , 0.00410931,\n",
       "        0.03255538]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModel accuracy:\u001b[0m 46.76%\n",
      "________________________________________________________________________________\n",
      "\u001b[1mConfusion matrix:\u001b[0m\n",
      " [[795   0   0 ...   0   0   0]\n",
      " [  6   0   0 ...   0   0   0]\n",
      " [ 48   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  7   0   0 ...   0   0   0]\n",
      " [  7   0   0 ...   0   0   0]\n",
      " [ 71   0   0 ...   0   0   0]]\n",
      "________________________________________________________________________________\n",
      "\u001b[1mClassification report:\u001b[0m\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      1.00      0.64       795\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.00      0.00      0.00        48\n",
      "           3       0.00      0.00      0.00        40\n",
      "           4       0.00      0.00      0.00        20\n",
      "           5       0.00      0.00      0.00        26\n",
      "           6       0.00      0.00      0.00        37\n",
      "           7       0.00      0.00      0.00        14\n",
      "           8       0.00      0.00      0.00       132\n",
      "           9       0.00      0.00      0.00        50\n",
      "          10       0.00      0.00      0.00        28\n",
      "          11       0.00      0.00      0.00         6\n",
      "          12       0.00      0.00      0.00        52\n",
      "          13       0.00      0.00      0.00        29\n",
      "          14       0.00      0.00      0.00        24\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00        17\n",
      "          17       0.00      0.00      0.00        16\n",
      "          18       0.00      0.00      0.00        18\n",
      "          19       0.00      0.00      0.00        43\n",
      "          20       0.00      0.00      0.00         7\n",
      "          21       0.00      0.00      0.00         6\n",
      "          22       0.00      0.00      0.00        58\n",
      "          23       0.00      0.00      0.00        23\n",
      "          24       0.00      0.00      0.00        11\n",
      "          25       0.00      0.00      0.00         9\n",
      "          26       0.00      0.00      0.00        19\n",
      "          27       0.00      0.00      0.00         8\n",
      "          28       0.00      0.00      0.00        14\n",
      "          29       0.00      0.00      0.00        22\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00         9\n",
      "          32       0.00      0.00      0.00         8\n",
      "          33       0.00      0.00      0.00         7\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00        71\n",
      "\n",
      "   micro avg       0.47      0.47      0.47      1700\n",
      "   macro avg       0.01      0.03      0.02      1700\n",
      "weighted avg       0.22      0.47      0.30      1700\n",
      " samples avg       0.47      0.47      0.47      1700\n",
      "\n",
      "________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\huggingface\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "classification_summary(y_test_cat, y_pred, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
